Having constructed an index on a document collection, queries need to 
be matched to documents and a list of answers returned. We need a ranking algorithm based on good mathematical retrieval models to 
return relevant documents at top of the ordered list, leading to high effectiveness. 
Three well-known retrieval models are~\citep[p. 233]{croft2010search}: (1) vector space models (e.g., term frequency and inverse document frequency (TF-IDF)), (2) probabilistic models (e.g., BM25\footnote{BM stands for Best Match, and 25 is just a numbering scheme used by~\cite{robertson1994some} to keep track of weighting variants.}), and (3) Language Models~(LM). 

\paragraph{The Vector Space Model}
\ \\
In a vector space model, documents and queries are represented by vectors of term weights, and the collection is represented by a matrix of term weights as follows: 
\begin{displaymath} 
D_{i}=[d_{i1}, d_{i2}, d_{i3}, \ldots , d_{im}],
\end{displaymath}
\begin{displaymath} 
Q=[q_{1}, q_{2}, q_{3}, \ldots , q_{m}],
\end{displaymath}
\begin{displaymath} 
C=
%\begin{matrix} D_{1} \\ D_{2} \\ D_{3} \\ \vdots\\ D_{N} \\\end{matrix}
\begin{bmatrix}
        d_{11} & d_{12} & d_{13} & \cdots & d_{1m}\\
        d_{21} & d_{22} & d_{23} & \cdots & d_{2m}\\
        d_{31} & d_{32} & d_{33} & \cdots & d_{3m}\\
        \vdots\\
        d_{N1} & d_{N2} & d_{N3} & \cdots & d_{Nm}
     \end{bmatrix},
\end{displaymath}
%\capstartfalse
%\begin{figure}[htpb]
%   \centering
%   \includegraphics[width=.45\textwidth,height=35mm]{figs/vsm-matrix.jpg}
%\end{figure}
%\capstarttrue
%\FloatBarrier 
\noindent
where $ D_{i} $ is a document in the collection $ C $, $ d_{ik} $ is a weight for each term $ t_{k} $ in the document $ D_{i} $, and $ q_{k} $\footnote{We ignore indices to simplify the further equations in this thesis.} represents a term in the query $ Q $. The collection is represented by the matrix $C_{Nm}$, where $N$ is the number of documents in the collection and $m$ is the number of all vocabularies. If a term does not appear in a document or a query, the weight for that particular term will be zero. 

The TF-IDF weighting function multiplies the occurrence of each term in the document ($ c(t_{k},Di)$)
by the inverse document frequency ($ idf $) measure. $ idf $ measures the importance of a term in the collection: 
\begin{equation}
idf(t_{k})=\log\frac{N+1}{df(t_{k})},
\label{eq:idf}
\end{equation}
where $ df(t_{k}) $ is the number of documents in the collection, which contain at least one occurrence of the term $ t_{k} $, and $ N $ is the number of documents in the collection. 

Given a query $Q$, documents are ranked based on the overlap score measure. The TF-IDF score of a document $D$ is the sum, over all query terms, of the TF-IDF weight of each query term $q$ in $D$. After pivoted normalisation, the TF-IDF score for each document is calculated as follows~\citep{bache2010improving}:
\begin{equation}
TFIDF(Q,D)=\sum\limits_{q \in Q\cap D}\frac{c(q,D)\times idf(q)}{(1-b)+b.\frac{|D|}{avdl}},
\label{eq:tfidf}
\end{equation}
where $ |D| $ is the size of the document (i.e, the number of words) and $ avdl $ is the average document length, $ c(q,D)$ is the number of occurrence of each query term in the document $D$, and $idf(q)$ is the importance of each query term in the collection. TF-IDF model scores a document higher if more query terms are present or these terms are rarer in the collection. The parameter $ b $ is set to 0.75 to be the same as the BM25 model as will be described below.
\paragraph{Probabilistic Models}
\ \\
BM25 is a popular and effective ranking algorithm, which extends the scoring function for the binary independence model~\citep[p. 232]{manning2008introduction} to include document and query term weights. Each document is scored based on the BM25 weighting scheme --- often called the Okapi weighting --- as follows:
\begin{equation}
BM25(Q,D)=\sum\limits_{q \in Q\cap D}\Bigg(\log\frac{N+1}{df(q)}\Bigg)\Bigg(\frac{(k_{1}+1)c(q,D)}{k_{1}((1-b)+b.\frac{|D|}{avdl})+c(q,D)}\Bigg).
\label{eq:idfbm25}
\end{equation}
The variable $ k_{1} $ is a positive tuning parameter that calibrates the document term frequency scaling. The setting of $ k_{1}=0 $ corresponds to a binary model (i.e., no term frequency), and setting a large value for $ k_{1} $ corresponds to using raw term
frequency. The parameter $ b $ is also used for tuning ($ 0 \leq b \leq 1 $) which determines the scaling by document length: $ b = 1 $ corresponds to fully scaling the term weight by the document length, while $ b = 0 $ corresponds to no length normalisation. 

If the query is long, then we might also use similar weighting for query terms. This is appropriate if the queries are paragraph long information needs, but unnecessary for short queries. 
In this case, BM25 weighting function is calculated as follows:
\begin{equation}
BM25(Q,D)=\sum\limits_{q \in Q\cap D}\log\Bigg(\frac{N+1}{df(q)}\Bigg)\Bigg(\frac{(k_{1}+1)c(q,D)}{k_{1}((1-b)+b\frac{|D|}{avdl})+c(q,D)}\Bigg)\Bigg(\frac{(k_{3}+1)c(q,Q)}{k_{3}+c(q,Q)}\Bigg),
\label{eq:idfbm25}
\end{equation}
where $ c(q,Q) $ is the frequency of term $ q $ in the query $ Q $, and $ k_{3} $ being another positive tuning parameter that this time calibrates term frequency scaling of the query. In the equation presented, there is no length normalisation of
queries because retrieval is being done with respect to a single fixed query. The tuning parameters of these equations should ideally be set to optimise performance on a development test collection. That is, we can search for values of these parameters that maximise performance on a separate development test collection (either manually or with optimisation methods such as grid search or something more advanced), and then use these parameters on the actual test collection. In the absence of such optimisation, experiments have shown reasonable values are to set $ k_{1} $ and $ k_{2} $ to a value between 1.2 and 2, and b = 0.75~\citep{manning2008introduction}.

\paragraph{Language Models with Terms Smoothing}
\ \\
\input{background/LM}